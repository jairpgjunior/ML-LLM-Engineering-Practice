
## üöÄ Project Overview

This repository documents my journey through Machine Learning and Large Language Models, exploring industry-standard tools and frameworks.

## üìö Notebooks & Projects

#### [1. Handwritten Digit Classification with MLP](./1-classification-of-handwritten-digits-using-an-mlp.ipynb)
- **Technologies**: PyTorch, Neural Networks
- **Key Implementations**:
  - Multi-Layer Perceptron (MLP) architecture
  - MNIST dataset processing and handling
  - Neural network training and optimization
- **Learning Outcomes**:
  - Fundamentals of neural network architecture
  - Implementation of backpropagation
  - Image data preprocessing techniques

#### [2. PyTorch and Hugging Face Scavenger Hunt](./2-pytorch-and-hugging-face-scavenger-huntscavenger-hunt.ipynb)
- **Technologies**: PyTorch, Hugging Face Transformers
- **Key Implementations**:
  - Exploration of PyTorch fundamentals
  - Hugging Face ecosystem navigation
  - Model discovery and implementation
- **Learning Outcomes**:
  - Deep understanding of PyTorch API
  - Hugging Face Hub utilization
  - Model selection and evaluation
  - Framework integration best practices


#### [3. Transfer Learning with MobileNetV3](./3-transfer-learning-using-mobilenetv3.ipynb)
- **Technologies**: PyTorch, MobileNetV3
- **Key Implementations**:
  - Transfer learning using pre-trained MobileNetV3
  - Fine-tuning for custom image classification
  - Model optimization for mobile deployment
- **Learning Outcomes**:
  - Efficient model adaptation techniques
  - Mobile-optimized architecture understanding
  - Modern CNN architectures and their applications

#### [4. Spam Email Classification using Foundation Models](./4-use-a-foundation-model-to-build-a-spam-email-classifier.ipynb)
- **Technologies**: Transformers, HuggingFace
- **Key Implementations**:
  - Foundation model adaptation for classification
  - Email text preprocessing
  - Binary classification fine-tuning
- **Learning Outcomes**:
  - Foundation model utilization
  - Text classification pipelines
  - Model evaluation for binary tasks

#### [5. BERT Sentiment Classification](./5-create-a-bert-sentiment-classifier.ipynb)
- **Technologies**: BERT, PyTorch, Transformers
- **Key Implementations**:
  - BERT-based sentiment analysis
  - Text preprocessing for BERT
  - Fine-tuning transformer models
- **Learning Outcomes**:
  - BERT architecture understanding
  - Sentiment analysis techniques
  - Transformer model fine-tuning

#### [6. Token Generation Implementation](./6-generating-one-token-at-a-time.ipynb)
- **Technologies**: Transformers, PyTorch
- **Key Implementations**:
  - Autoregressive token generation
  - Implementation of generation strategies
  - Text generation pipelines
- **Learning Outcomes**:
  - Language model inference
  - Token generation algorithms
  - Text generation optimization

#### [7. BERT Full Fine-tuning](./7-full-fine-tuning-bert.ipynb)
- **Technologies**: BERT, PyTorch, Transformers
- **Key Implementations**:
  - Complete BERT model fine-tuning
  - Custom dataset adaptation
  - Advanced training techniques
- **Learning Outcomes**:
  - Advanced fine-tuning strategies
  - Model optimization techniques
  - Large-scale training management

---

‚≠ê Star this repository if you find it interesting!